import xgboost as xgb
from time import time
import numpy as np
#import pandas as pd
from utils import get_all_files_features_and_labels, seperate_to_train_and_test
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier


def learn_with_XGBClassifier(train_data, train_lbl, test_files, test_lbl, lr=0.22, n_esti=40, seed=123):
    train_time = time()
    xg_cl = xgb.XGBClassifier(objective='multi:softmax', num_class=10, learning_rate=lr,
                              n_estimators=n_esti, seed=seed)
    xg_cl.fit(train_data, train_lbl)
    train_time = time() - train_time
    test_time = time()
    preds = xg_cl.predict(test_files)
    test_time = time() - test_time
    accuracy = float(np.sum(preds == test_lbl)) / test_lbl.shape[0]
    return {"train time: ": train_time, "test time: ": test_time, "accuracy: ": accuracy*100}


def learn_with_dt(train_files, train_lbl, test_file, test_lbl):
    train_time = time()
    xg_dt = DecisionTreeClassifier()
    xg_dt = xg_dt.fit(train_files, train_lbl)
    train_time = time() - train_time
    test_time = time()
    preds = xg_dt.predict(test_file)
    test_time = time() - test_time
    accuracy = float(np.sum(preds == test_lbl)) / test_lbl.shape[0]
    return {"train time: ": train_time, "test time: ": test_time, "accuracy: ": accuracy*100}

# Crossvalidation to improve hyper parameters
def learn_with_cv(X, Y):
    t = time()
    early_stopping = 10
    churn_dmatrix = xgb.DMatrix(X, Y)
    params = {"objective": "multi:softmax", "max_depth": 4, "num_class": 10, "silent": 1,
              "seed": 99}
    cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=6, num_boost_round=30,
                        metrics="merror", as_pandas=True, early_stopping_rounds=early_stopping)
    t = time()-t
    print(cv_results)
    return {"time: ": t, "params: ": params, "early stopping": early_stopping, "accuracy": cv_results}


def main():
    file = open("results.txt", "a")
    learner = "Classifier"

    print("start processing input")
    features, labels, ngrams_sets, i2ngram, ngram2i, labels_dict = get_all_files_features_and_labels("./files/train50","./files/benign50",[4], use_unknown=False)
    X, Y = np.array(features), np.array(labels)
    if learner == "Classifier":
        #X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=111)
        X_train, X_test, y_train, y_test = seperate_to_train_and_test(
            features, labels)

        print("Start learning counter")
        print("Learn with XGBClassifier")
        lr=0.22
        n_esti=40
        seed=123
        train_time = time()
        xg_cl = xgb.XGBClassifier(objective='multi:softmax', num_class=10, learning_rate=lr,n_estimators=n_esti, seed=seed)
        xg_cl.fit(np.array(X_train), np.array(y_train))
        train_time = time() - train_time
        test_time = time()
        preds = xg_cl.predict(np.array(X_test))
        test_time = time() - test_time
        accuracy = float(np.sum(preds == np.array(y_test))) / np.array(y_test).shape[0]
        print ("train time: ", train_time, "test time: ", test_time, "accuracy: ", accuracy*100)

        X_train, X_test, y_train, y_test = (np.array(X_train) > 0).astype(int), (np.array(X_test) > 0).astype(int), np.array(y_train), np.array(y_test)
        
        print("Start learning again using bool")
        print("learn_with_XGBClassifier")
        train_time = time()
        xg_cl = xgb.XGBClassifier(objective='multi:softmax', num_class=10, learning_rate=lr,n_estimators=n_esti, seed=seed)
        xg_cl.fit(X_train, y_train)
        train_time = time() - train_time
        test_time = time()
        preds = xg_cl.predict(X_test)
        test_time = time() - test_time
        accuracy = float(np.sum(preds == y_test)) / y_test.shape[0]
        print ("train time: ", train_time, "test time: ", test_time, "accuracy: ", accuracy*100)
        pass

    print("Strat Learning CV")
    res = learn_with_cv((X > 0).astype(int), Y)
    import pprint
    pp = pprint.PrettyPrinter(indent=4)
    pp.pprint(res)
    num_res = " Real accuracy: {}".format((1-res["accuracy"][u'test-merror-mean'][-1]) * 100)
    pp.pprint(num_res)
    file.writelines(str(res))
    file.writelines(str(num_res))
    file.writelines("\n-----------------------------------------------------------------------")
    file.close()


if __name__ == "__main__":
    main()
